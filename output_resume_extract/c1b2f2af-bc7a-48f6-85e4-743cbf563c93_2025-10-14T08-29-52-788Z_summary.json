{
  "filename": "c1b2f2af-bc7a-48f6-85e4-743cbf563c93.pdf",
  "timestamp": "2025-10-14T08:29:52.788Z",
  "processingTime": 27508,
  "confidence": 93,
  "extractedData": {
    "name": "Diksha Kamble",
    "email": "dkdiksha20@gmail.com",
    "phone": "+91-9579338493",
    "title": "Data Scientist",
    "location": "Pune, Maharashtra",
    "summary": "Data Scientist with 4 Years of Experience | Passionate about Harnessing Machine Learning, NLP, Generative AI, Deep Learning, and Cloud Technologies to Solve Complex Problems | Skilled in LLM Fine-Tuning, Large Dataset Management, and Transforming Data into Innovative Business Solutions.",
    "experience": [
      {
        "jobTitle": "Data Scientist",
        "company": "Persistent Systems",
        "duration": "05/2021 - Present",
        "startDate": "2021-05",
        "endDate": "Present",
        "techUsed": [
          "scikit learn",
          "Seaborn",
          "Matplotlib",
          "Pandas",
          "Numpy",
          "HuggingFace",
          "LangChain"
        ],
        "description": "To Identify valuable real-time data & automate the collection process. To undertake the prepossessing of supervised & unsupervised learning data. To analyze large amounts of data information, & discover trends and Patterns. Present information using data visualization techniques to identify the flow. Communicate & propose innovative solutions & strategies to business challenges. Analyzed data for insights, trends, patterns & extracting key information from structured & unstructured data. Feature extraction, data wrangling, & data transformation infrastructure. Design, implement, & maintain Machine learning, NLP, GenAI modelling & algorithms. Experience using ML & NLP libraries. Take ownership of the data science model end-to-end from data collection to model building. Solid understanding of the mathematics related to data science probability, statistics, linear algebra etc. Ability to understand business concerns and formulate them as technical problems that can be solved using data and math / stats / ML/ NLP /GenAI. Experience working as part of a product team, along with engineers and product managers, to define the problem and execute the data science solution. Good interpersonal skills & learn new technologies and undertake challenges.",
        "achievements": []
      }
    ],
    "education": [
      {
        "degree": "Bachelor of Science",
        "field": null,
        "university": "JB College of Science",
        "year": "2019",
        "percentage": null,
        "gpa": null,
        "location": null
      },
      {
        "degree": "Masters in Science",
        "field": null,
        "university": "Saint Francies De’Sales College",
        "year": "2021",
        "percentage": null,
        "gpa": null,
        "location": null
      }
    ],
    "skills": [
      "Python",
      "SQL",
      "NumPy",
      "Pandas",
      "Scikit-Learn",
      "Matplotlib",
      "Seaborn",
      "ChromaDB",
      "Pinecone",
      "MongoDB Atlas",
      "Faiss",
      "Weaviate",
      "Qdrant",
      "Flask API",
      "Postman",
      "FastAPI",
      "Streamlit",
      "Gradio",
      "Linear Regression",
      "Ridge",
      "Lasso",
      "Logistic Regression",
      "Naïve Bayes Classifier",
      "KNN",
      "SVM",
      "Decision Tree",
      "Random Forest",
      "PCA",
      "Ada-Boost",
      "XGBoost",
      "K-means Clustering",
      "Feature Engg",
      "Normalization",
      "Neural Networks",
      "CNN",
      "RNN",
      "LSTM",
      "GRU",
      "TensorFlow",
      "PyTorch",
      "Keras",
      "Hyper Parameter Tuning",
      "Transfer learning",
      "BOW",
      "TFIDF",
      "word2vec",
      "doc2vec",
      "FastText",
      "Glove",
      "Keypharse extraction",
      "Text classification",
      "Tokenization",
      "NLTK",
      "Spacy",
      "Gensim",
      "BERT",
      "BERT-Finetuning",
      "Model evaluation",
      "RAG",
      "Encoder",
      "Decoder",
      "Transformers",
      "LLM",
      "Tokenizers",
      "Attention Mechanism",
      "Langchain",
      "Huggingface library",
      "Huggingface pipeline",
      "Groq API",
      "OpenAI API",
      "Cohere API",
      "Anthropic API",
      "Claude",
      "Emedding Models",
      "Multimodal Models",
      "GPT Models",
      "OpenSource Models",
      "Prompt Engineering",
      "RAGAs Library",
      "Finetunning-LORA",
      "QLORA",
      "LangGraph",
      "LangSmith",
      "LlamaIndex",
      "Memory",
      "Tools & Agents",
      "Retrivals",
      "Chains",
      "LCEL",
      "VectorStores",
      "Agentic AI",
      "Autogen",
      "CrewAI",
      "AWS",
      "EC2",
      "Sagemaker",
      "ECS",
      "ECR",
      "S3",
      "AWS Bedrock",
      "lambda",
      "Textract",
      "API Gateway",
      "CoudWatch",
      "IAM",
      "VPC",
      "Azure Open AI",
      "Amazon OpenSearch",
      "CICD",
      "MLflow",
      "Docker",
      "Git",
      "Github",
      "Gitbash",
      "VS Code",
      "Google Colab",
      "Jupyter notebook",
      "Agile",
      "JIRA"
    ],
    "projects": [
      {
        "name": "Automated Classification of Customer Complaints for a Financial Institution",
        "description": "Developed and deployed a robust machine-learning solution for automating the classification of customer complaints, leveraging LSTM neural networks with pre-trained word embeddings, and fine-tuned BERT for enhanced contextual understanding.",
        "techUsed": [
          "Python",
          "LSTM",
          "BERT",
          "TensorFlow",
          "MongoDB",
          "Data Preprocessing"
        ],
        "duration": null,
        "url": null,
        "achievements": [
          "Model Development: Built and optimized an LSTM model for multi-class text classification, hyperparameter tuning to achieve high accuracy across complaint categories.",
          "Fine-tuned a pre-trained BERT model using Hugging Face for better contextual understanding and classification accuracy.",
          "Business Impact: Reduced complaint resolution, boosting customer satisfaction and operational efficiency. Ensured accurate categorization for regulatory compliance."
        ]
      },
      {
        "name": "AI-Powered Chatbot for Financial Data Processing",
        "description": "Built an AI-driven chatbot to process and retrieve financial data from diverse formats, enabling automated insights and enhanced user interaction.",
        "techUsed": [
          "LangChain",
          "LLM",
          "Hugging Face",
          "VectorDB",
          "Python"
        ],
        "duration": null,
        "url": null,
        "achievements": [
          "Implemented a robust RAG system to generate accurate, contextually relevant responses.",
          "Embedding & Retrieval: Utilized Hugging Face and LangChain for document retrieval, ensuring efficient search and contextualized responses.",
          "Deployment: Deployed chatbot using AWS, ensuring scalability and affordability.",
          "Business Impact: Enhanced data accessibility, reduced manual effort, and improved decision-making for financial analysts."
        ]
      },
      {
        "name": "Legal Document Assistant",
        "description": "Developed an AI-driven assistant to automate summarization and Q&A of legal contracts, improving efficiency for internal legal teams.",
        "techUsed": [
          "GenAI",
          "RAG",
          "Python",
          "Amazon Bedrock",
          "LangChain"
        ],
        "duration": null,
        "url": null,
        "achievements": [
          "Built a retrieval-augmented generation (RAG) system to extract and summarize key clauses from uploaded contracts.",
          "Automated the document processing and response generation pipeline for legal queries.",
          "Business Impact: Reduced contract review time by 75%, lowered cost per document."
        ]
      },
      {
        "name": "Automated Fraud Detection in Health Insurance Claims",
        "description": "Developed and deployed a machine-learning solution to detect fraudulent health insurance claims, achieving better accuracy and reducing manual review efforts.",
        "techUsed": [
          "Python",
          "Pandas",
          "Machine learning",
          "API Development"
        ],
        "duration": null,
        "url": null,
        "achievements": [
          "Model Development: Implemented multiple models, including Logistic Regression, Decision Trees, and SVM, with Random Forest yielding the highest accuracy. Hyperparameter optimization was performed using Grid Search.",
          "Deployment: Built and tested an API using Flask and Postman, integrated with the client’s online submission platform for real-time fraud detection.",
          "Business Impact: Improved fraud detection accuracy, reduced false positives, enhanced operational efficiency, and ensured compliance with industry regulations."
        ]
      }
    ],
    "certifications": []
  }
}
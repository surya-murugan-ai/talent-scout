{
  "filename": "0153b2b8-8d0a-4391-932e-3a64a19fb521.pdf",
  "timestamp": "2025-10-14T07:07:43.721Z",
  "processingTime": 66366,
  "confidence": 93,
  "rawText": "\n\nCONTACT\nWORK EXPERIENCE\nABOUT\n05/2021 - Present\nPERSISTENT SYSTEMS\nDATA SCIENTIST\n+91-9579338493\ndkdiksha20@gmail.com\nPune, Maharashtra\nTo Identify valuable real-time data & automate the collection\nTo Identify valuable real-time data & automate the collection\nprocess.\nprocess.\nTo undertake the prepossessing of supervised & unsupervised\nTo undertake the prepossessing of supervised & unsupervised\nlearning data.\nlearning data.\n \n \nTo  analyze  large  amounts  of  data  information,  &  discover\nTo  analyze  large  amounts  of  data  information,  &  discover\ntrends  and  Patterns.  Present  information  using  data\ntrends  and  Patterns.  Present  information  using  data\nvisualization techniques to identify the flow.\nvisualization techniques to identify the flow.\nCommunicate & propose innovative solutions & strategies to\nCommunicate & propose innovative solutions & strategies to\nbusiness challenges.\nbusiness challenges.\nAnalyzed data for insights, trends, patterns & extracting key\nAnalyzed data for insights, trends, patterns & extracting key\ninformation from structured & unstructured data.\ninformation from structured & unstructured data.\nFeature  extraction,  data  wrangling,  &  data  transformation\nFeature  extraction,  data  wrangling,  &  data  transformation\ninfrastructure.\ninfrastructure.\nDesign, implement, & maintain Machine learning, NLP, GenAI\nDesign, implement, & maintain Machine learning, NLP, GenAI\nmodelling & algorithms.\nmodelling & algorithms.\nExperience  using  ML  &  NLP  libraries,  such  as  scikit  learn,\nExperience  using  ML  &  NLP  libraries,  such  as  scikit  learn,\nSeaborn,   Matplotlib,   Pandas,   Numpy,   HuggingFace   &\nSeaborn,   Matplotlib,   Pandas,   Numpy,   HuggingFace   &\nLangChain ecosystem etc.\nLangChain ecosystem etc.\nTake ownership of the data science model end-to-end from\nTake ownership of the data science model end-to-end from\ndata collection to model building.\ndata collection to model building.\nSolid  understanding  of  the  mathematics  related  to  data\nSolid  understanding  of  the  mathematics  related  to  data\nscience probability, statistics, linear algebra etc.\nscience probability, statistics, linear algebra etc.\nAbility to understand business concerns and formulate them\nAbility to understand business concerns and formulate them\nas technical problems that can be solved using data and math\nas technical problems that can be solved using data and math\n/ stats / ML/ NLP /GenAI.\n/ stats / ML/ NLP /GenAI.\nExperience  working  as  part  of  a  product  team,  along  with\nExperience  working  as  part  of  a  product  team,  along  with\nengineers and product managers, to define the problem and\nengineers and product managers, to define the problem and\nexecute the data science solution.\nexecute the data science solution.\nGood  interpersonal  skills  &  learn  new  technologies  and\nGood  interpersonal  skills  &  learn  new  technologies  and\nundertake challenges.\nundertake challenges.\nData Scientist with 4 Years of Experience | Passionate about\nData Scientist with 4 Years of Experience | Passionate about\nHarnessing Machine Learning, NLP, Generative AI, Deep\nHarnessing Machine Learning, NLP, Generative AI, Deep\nLearning, and Cloud Technologies\nLearning, and Cloud Technologies\n  \n  \nto Solve Complex\nto Solve Complex\nProblems | Skilled in LLM Fine-Tuning, Large Dataset\nProblems | Skilled in LLM Fine-Tuning, Large Dataset\nManagement, and Transforming Data into Innovative\nManagement, and Transforming Data into Innovative\nBusiness Solutions.\nBusiness Solutions.\nTECHNICAL SKILLS\n \n \nLanguages:\nLanguages:\n Python, SQL\n Python, SQL\n \n \nPython Packages:\nPython Packages:\n NumPy, Pandas, Scikit-Learn,\n NumPy, Pandas, Scikit-Learn,\nMatplotlib, Seaborn.\nMatplotlib, Seaborn.\n \n \nVector Databases\nVector Databases\n: ChromaDB, Pinecone,\n: ChromaDB, Pinecone,\nMongoDB Atlas, Faiss, Weaviate, Qdrant.\nMongoDB Atlas, Faiss, Weaviate, Qdrant.\nWeb Stack\nWeb Stack\n: Flask API, Postman, FastAPI,\n: Flask API, Postman, FastAPI,\nStreamlit,\nStreamlit,\n  \n  \nGradio.\nGradio.\nMachine Learning\nMachine Learning\n: Linear Regression, Ridge &\n: Linear Regression, Ridge &\nLasso, Logistic Regression, Naïve Bayes\nLasso, Logistic Regression, Naïve Bayes\nClassifier,KNN, SVM, Decision Tree, Random\nClassifier,KNN, SVM, Decision Tree, Random\nForest,PCA, Ada-Boost, XGBoost, K- means\nForest,PCA, Ada-Boost, XGBoost, K- means\nClustering, Feature Engg, Normalization.\nClustering, Feature Engg, Normalization.\nDeep Learning\nDeep Learning\n: Neural Networks, CNN, RNN,\n: Neural Networks, CNN, RNN,\nLSTM, GRU, TensorFlow, PyTorch, Keras, Hyper\nLSTM, GRU, TensorFlow, PyTorch, Keras, Hyper\nParameter Tuning, Transfer learning.\nParameter Tuning, Transfer learning.\nNLP\nNLP\n: BOW, TFIDF, word2vec, doc2vec,\n: BOW, TFIDF, word2vec, doc2vec,\n  \n  \nFastText,\nFastText,\nGlove, Keypharse extraction, Text classification,\nGlove, Keypharse extraction, Text classification,\nTokenization,\nTokenization,\n  \n  \nNLTK , Spacy, Gensim, BERT, BERT-\nNLTK , Spacy, Gensim, BERT, BERT-\nFinetuning, Model evaluation.\nFinetuning, Model evaluation.\nGenAI: \nGenAI: \nRAG,\nRAG,\n \n \nEncoder, Decoder,\nEncoder, Decoder,\n \n \nTransformers,\nTransformers,\nLLM, Tokenizers, Attention Mechanism,\nLLM, Tokenizers, Attention Mechanism,\nLangchain, Huggingface library, Huggingface\nLangchain, Huggingface library, Huggingface\npipeline, Groq API, OpenAI API, Cohere API,\npipeline, Groq API, OpenAI API, Cohere API,\nAnthropic API, Claude, Emedding Models,\nAnthropic API, Claude, Emedding Models,\nMultimodal Models, GPT Models, OpenSource\nMultimodal Models, GPT Models, OpenSource\nModels,\nModels,\n  \n  \nPrompt Engineering, RAGAs Library,\nPrompt Engineering, RAGAs Library,\nFinetunning-LORA, QLORA, LangGraph,\nFinetunning-LORA, QLORA, LangGraph,\nLangSmith,\nLangSmith,\n  \n  \nLlamaIndex, Memory, Tools &\nLlamaIndex, Memory, Tools &\nAgents, Retrivals, Chains, LCEL,VectorStores,\nAgents, Retrivals, Chains, LCEL,VectorStores,\nAgentic AI, Autogen, CrewAI.\nAgentic AI, Autogen, CrewAI.\n \n \nCloud & MLOps:\nCloud & MLOps:\n AWS, EC2, Sagemaker, ECS,\n AWS, EC2, Sagemaker, ECS,\nECR, S3, AWS Bedrock, lambda, Textract, API\nECR, S3, AWS Bedrock, lambda, Textract, API\nGateway, CoudWatch, IAM, VPC, Azure Open AI,\nGateway, CoudWatch, IAM, VPC, Azure Open AI,\nAmazon OpenSearch, CICD, MLflow, Docker,\nAmazon OpenSearch, CICD, MLflow, Docker,\n \n \nVersion control\nVersion control\n:\n:\n Git, Github, Gitbash\n Git, Github, Gitbash\n \n \nIDE: \nIDE: \nVS Code, Google Colab, Jupyter notebook\nVS Code, Google Colab, Jupyter notebook\n \n \n \n \nProject Management tool:\nProject Management tool:\n  \n  \nAgile, JIRA\nAgile, JIRA\nEDUCATIONS\nBachelor of Science (2016-2019)\nBachelor of Science (2016-2019)\nJB College of Science\nJB College of Science\nMasters in Science (2019-2021)\nMasters in Science (2019-2021)\nSaint Francies De’Sales College\nSaint Francies De’Sales College\n      \n      \n---------------------------------------------------------------------\n---------------------------------------------------------------------\n DIKSHA KAMBLE\nD A T A   S C I E N T I S T\n\nProject-1: Automated Classification of Customer Complaints for a Financial Institution.\nProject-1: Automated Classification of Customer Complaints for a Financial Institution.\nOverview: \nOverview: \nDeveloped and deployed a robust machine-learning solution for automating the\nDeveloped and deployed a robust machine-learning solution for automating the\nclassification of customer complaints, leveraging LSTM neural networks with pre-trained word\nclassification of customer complaints, leveraging LSTM neural networks with pre-trained word\nembeddings, and fine-tuned BERT for enhanced contextual understanding.\nembeddings, and fine-tuned BERT for enhanced contextual understanding.\nKey Contributions:\nKey Contributions:\nModel Development: Built and optimized an LSTM model for multi-class text classification,\nModel Development: Built and optimized an LSTM model for multi-class text classification,\nhyperparameter tuning to achieve high accuracy across\nhyperparameter tuning to achieve high accuracy across\n  \n  \ncomplaint categories.\ncomplaint categories.\n \n \nFine-tuned a pre-trained BERT model using Hugging Face for better contextual understanding\nFine-tuned a pre-trained BERT model using Hugging Face for better contextual understanding\nand classification accuracy.\nand classification accuracy.\nBusiness Impact: Reduced complaint resolution, boosting customer satisfaction and operational\nBusiness Impact: Reduced complaint resolution, boosting customer satisfaction and operational\nefficiency. Ensured accurate categorization for regulatory compliance.\nefficiency. Ensured accurate categorization for regulatory compliance.\nTechnologies: \nTechnologies: \nPython, LSTM, BERT, TensorFlow, MongoDB, Data Preprocessing.]\nPython, LSTM, BERT, TensorFlow, MongoDB, Data Preprocessing.]\nProject 2: AI-Powered Chatbot for Financial Data Processing.\nProject 2: AI-Powered Chatbot for Financial Data Processing.\nOverview: \nOverview: \nBuilt an AI-driven chatbot to process and retrieve financial data from diverse formats,\nBuilt an AI-driven chatbot to process and retrieve financial data from diverse formats,\nenabling automated insights and enhanced user interaction.\nenabling automated insights and enhanced user interaction.\nKey Contributions:\nKey Contributions:\nImpl\nImpl\nemented a robust RAG system to generate accurate, contextually relevant responses.\nemented a robust RAG system to generate accurate, contextually relevant responses.\nEmbedding & Retrieval: Utilized Hugging Face and LangChain for document retrieval, ensuring\nEmbedding & Retrieval: Utilized Hugging Face and LangChain for document retrieval, ensuring\nefficient search and contextualized responses.\nefficient search and contextualized responses.\nDeployment: Deployed chatbot using AWS, ensuring scalability and affordability.\nDeployment: Deployed chatbot using AWS, ensuring scalability and affordability.\nBusiness Impact: Enhanced data accessibility, reduced manual effort, and improved decision-\nBusiness Impact: Enhanced data accessibility, reduced manual effort, and improved decision-\nmaking for financial analysts.\nmaking for financial analysts.\nTechnologies: \nTechnologies: \nLangChain, LLM, Hugging Face, VectorDB, Python.\nLangChain, LLM, Hugging Face, VectorDB, Python.\nProject 3: Legal Document Assistant.\nProject 3: Legal Document Assistant.\nOverview:\nOverview:\n Developed an AI-driven assistant to automate summarization and Q&A of legal contracts,\n Developed an AI-driven assistant to automate summarization and Q&A of legal contracts,\nimproving efficiency for internal legal teams.\nimproving efficiency for internal legal teams.\nKey Contributions:\nKey Contributions:\nBuilt a retrieval-aug\nBuilt a retrieval-aug\nmented generation (RAG) system to extract and summarize key clauses\nmented generation (RAG) system to extract and summarize key clauses\nfrom uploaded contracts.\nfrom uploaded contracts.\nAutomated the document processing and response generation pipeline for legal queries.\nAutomated the document processing and response generation pipeline for legal queries.\nBusiness Impact: Reduced contract review time by 75%, lowered cost per document.\nBusiness Impact: Reduced contract review time by 75%, lowered cost per document.\nTechnologies\nTechnologies\n: GenAI, RAG, Python, Amazon Bedrock, LangChain\n: GenAI, RAG, Python, Amazon Bedrock, LangChain\nProject-4: Automated Fraud Detection in Health Insurance Claims.\nProject-4: Automated Fraud Detection in Health Insurance Claims.\nOverview\nOverview\n: Developed and deployed a machine-learning solution to detect fraudulent health\n: Developed and deployed a machine-learning solution to detect fraudulent health\ninsurance claims, achieving better accuracy and reducing manual review efforts.\ninsurance claims, achieving better accuracy and reducing manual review efforts.\nKey Contributions:\nKey Contributions:\nModel Development: Implemented multiple models, including Logistic Regression, Decision\nModel Development: Implemented multiple models, including Logistic Regression, Decision\nTrees, and SVM, with Random Forest yielding the highest accuracy. Hyperparameter\nTrees, and SVM, with Random Forest yielding the highest accuracy. Hyperparameter\noptimization was performed using Grid Search.\noptimization was performed using Grid Search.\nDeployment: Built and tested an API using Flask and Postman, integrated with the client’s online\nDeployment: Built and tested an API using Flask and Postman, integrated with the client’s online\nsubmission platform for real-time fraud detection.\nsubmission platform for real-time fraud detection.\nBusiness Impact: Improved fraud detection accuracy, reduced false positives, enhanced\nBusiness Impact: Improved fraud detection accuracy, reduced false positives, enhanced\noperational efficiency, and ensured compliance with industry regulations.\noperational efficiency, and ensured compliance with industry regulations.\nTechnologies\nTechnologies\n: Python, Pandas,Machine learning, API Development.\n: Python, Pandas,Machine learning, API Development.\nPROJECTS",
  "extractedData": {
    "name": "Diksha Kamble",
    "email": "dkdiksha20@gmail.com",
    "phone": "+91-9579338493",
    "linkedinUrl": null,
    "githubUrl": null,
    "portfolioUrl": null,
    "location": "Pune, Maharashtra",
    "title": "Data Scientist",
    "summary": "Data Scientist with 4 Years of Experience | Passionate about Harnessing Machine Learning, NLP, Generative AI, Deep Learning, and Cloud Technologies to Solve Complex Problems | Skilled in LLM Fine-Tuning, Large Dataset Management, and Transforming Data into Innovative Business Solutions.",
    "experience": [
      {
        "jobTitle": "Data Scientist",
        "company": "Persistent Systems",
        "duration": "05/2021 - Present",
        "startDate": "2021-05",
        "endDate": "Present",
        "techUsed": [
          "scikit learn",
          "Seaborn",
          "Matplotlib",
          "Pandas",
          "Numpy",
          "HuggingFace",
          "LangChain"
        ],
        "description": "To Identify valuable real-time data & automate the collection process. To undertake the prepossessing of supervised & unsupervised learning data. To analyze large amounts of data information, & discover trends and Patterns. Present information using data visualization techniques to identify the flow. Communicate & propose innovative solutions & strategies to business challenges. Analyzed data for insights, trends, patterns & extracting key information from structured & unstructured data. Feature extraction, data wrangling, & data transformation infrastructure. Design, implement, & maintain Machine learning, NLP, GenAI modelling & algorithms. Experience using ML & NLP libraries, such as scikit learn, Seaborn, Matplotlib, Pandas, Numpy, HuggingFace & LangChain ecosystem etc. Take ownership of the data science model end-to-end from data collection to model building. Solid understanding of the mathematics related to data science probability, statistics, linear algebra etc. Ability to understand business concerns and formulate them as technical problems that can be solved using data and math / stats / ML/ NLP /GenAI. Experience working as part of a product team, along with engineers and product managers, to define the problem and execute the data science solution. Good interpersonal skills & learn new technologies and undertake challenges.",
        "achievements": []
      }
    ],
    "education": [
      {
        "degree": "Bachelor of Science",
        "field": null,
        "university": "JB College of Science",
        "year": "2019",
        "percentage": null,
        "gpa": null,
        "location": null
      },
      {
        "degree": "Masters in Science",
        "field": null,
        "university": "Saint Francies De’Sales College",
        "year": "2021",
        "percentage": null,
        "gpa": null,
        "location": null
      }
    ],
    "projects": [
      {
        "name": "Automated Classification of Customer Complaints for a Financial Institution",
        "description": "Developed and deployed a robust machine-learning solution for automating the classification of customer complaints, leveraging LSTM neural networks with pre-trained word embeddings, and fine-tuned BERT for enhanced contextual understanding.",
        "techUsed": [
          "Python",
          "LSTM",
          "BERT",
          "TensorFlow",
          "MongoDB",
          "Data Preprocessing"
        ],
        "duration": null,
        "url": null,
        "achievements": [
          "Model Development: Built and optimized an LSTM model for multi-class text classification, hyperparameter tuning to achieve high accuracy across complaint categories.",
          "Fine-tuned a pre-trained BERT model using Hugging Face for better contextual understanding and classification accuracy.",
          "Business Impact: Reduced complaint resolution, boosting customer satisfaction and operational efficiency. Ensured accurate categorization for regulatory compliance."
        ]
      },
      {
        "name": "AI-Powered Chatbot for Financial Data Processing",
        "description": "Built an AI-driven chatbot to process and retrieve financial data from diverse formats, enabling automated insights and enhanced user interaction.",
        "techUsed": [
          "LangChain",
          "LLM",
          "Hugging Face",
          "VectorDB",
          "Python"
        ],
        "duration": null,
        "url": null,
        "achievements": [
          "Implemented a robust RAG system to generate accurate, contextually relevant responses.",
          "Embedding & Retrieval: Utilized Hugging Face and LangChain for document retrieval, ensuring efficient search and contextualized responses.",
          "Deployment: Deployed chatbot using AWS, ensuring scalability and affordability.",
          "Business Impact: Enhanced data accessibility, reduced manual effort, and improved decision-making for financial analysts."
        ]
      },
      {
        "name": "Legal Document Assistant",
        "description": "Developed an AI-driven assistant to automate summarization and Q&A of legal contracts, improving efficiency for internal legal teams.",
        "techUsed": [
          "GenAI",
          "RAG",
          "Python",
          "Amazon Bedrock",
          "LangChain"
        ],
        "duration": null,
        "url": null,
        "achievements": [
          "Built a retrieval-augmented generation (RAG) system to extract and summarize key clauses from uploaded contracts.",
          "Automated the document processing and response generation pipeline for legal queries.",
          "Business Impact: Reduced contract review time by 75%, lowered cost per document."
        ]
      },
      {
        "name": "Automated Fraud Detection in Health Insurance Claims",
        "description": "Developed and deployed a machine-learning solution to detect fraudulent health insurance claims, achieving better accuracy and reducing manual review efforts.",
        "techUsed": [
          "Python",
          "Pandas",
          "Machine learning",
          "API Development"
        ],
        "duration": null,
        "url": null,
        "achievements": [
          "Model Development: Implemented multiple models, including Logistic Regression, Decision Trees, and SVM, with Random Forest yielding the highest accuracy. Hyperparameter optimization was performed using Grid Search.",
          "Deployment: Built and tested an API using Flask and Postman, integrated with the client’s online submission platform for real-time fraud detection.",
          "Business Impact: Improved fraud detection accuracy, reduced false positives, enhanced operational efficiency, and ensured compliance with industry regulations."
        ]
      }
    ],
    "achievements": [],
    "certifications": [],
    "skills": [
      "Python",
      "SQL",
      "NumPy",
      "Pandas",
      "Scikit-Learn",
      "Matplotlib",
      "Seaborn",
      "ChromaDB",
      "Pinecone",
      "MongoDB Atlas",
      "Faiss",
      "Weaviate",
      "Qdrant",
      "Flask API",
      "Postman",
      "FastAPI",
      "Streamlit",
      "Gradio",
      "Linear Regression",
      "Ridge & Lasso",
      "Logistic Regression",
      "Naïve Bayes Classifier",
      "KNN",
      "SVM",
      "Decision Tree",
      "Random Forest",
      "PCA",
      "Ada-Boost",
      "XGBoost",
      "K-means Clustering",
      "Feature Engg",
      "Normalization",
      "Neural Networks",
      "CNN",
      "RNN",
      "LSTM",
      "GRU",
      "TensorFlow",
      "PyTorch",
      "Keras",
      "Hyper Parameter Tuning",
      "Transfer learning",
      "BOW",
      "TFIDF",
      "word2vec",
      "doc2vec",
      "FastText",
      "Glove",
      "Keypharse extraction",
      "Text classification",
      "Tokenization",
      "NLTK",
      "Spacy",
      "Gensim",
      "BERT",
      "BERT-Finetuning",
      "Model evaluation",
      "RAG",
      "Encoder",
      "Decoder",
      "Transformers",
      "LLM",
      "Tokenizers",
      "Attention Mechanism",
      "Langchain",
      "Huggingface library",
      "Huggingface pipeline",
      "Groq API",
      "OpenAI API",
      "Cohere API",
      "Anthropic API",
      "Claude",
      "Emedding Models",
      "Multimodal Models",
      "GPT Models",
      "OpenSource Models",
      "Prompt Engineering",
      "RAGAs Library",
      "Finetunning-LORA",
      "QLORA",
      "LangGraph",
      "LangSmith",
      "LlamaIndex",
      "Memory",
      "Tools & Agents",
      "Retrivals",
      "Chains",
      "LCEL",
      "VectorStores",
      "Agentic AI",
      "Autogen",
      "CrewAI",
      "AWS",
      "EC2",
      "Sagemaker",
      "ECS",
      "ECR",
      "S3",
      "AWS Bedrock",
      "lambda",
      "Textract",
      "API Gateway",
      "CoudWatch",
      "IAM",
      "VPC",
      "Azure Open AI",
      "Amazon OpenSearch",
      "CICD",
      "MLflow",
      "Docker",
      "Git",
      "Github",
      "Gitbash",
      "VS Code",
      "Google Colab",
      "Jupyter notebook",
      "Agile",
      "JIRA"
    ],
    "interests": [],
    "languages": [],
    "salary": null,
    "availability": null,
    "remotePreference": null,
    "visaStatus": null,
    "originalData": {
      "filename": "0153b2b8-8d0a-4391-932e-3a64a19fb521.pdf",
      "rawText": "CONTACT WORK EXPERIENCE ABOUT 05/2021 - Present PERSISTENT SYSTEMS DATA SCIENTIST +91-9579338493 dkdiksha20@gmail.com Pune, Maharashtra To Identify valuable real-time data & automate the collection To Identify valuable real-time data & automate the collection process. process. To undertake the prepossessing of supervised & unsupervised To undertake the prepossessing of supervised & unsupervised learning data. learning data. To analyze large amounts of data information, & discover To analyze large amounts of data information, & discover trends and Patterns. Present information using data trends and Patterns. Present information using data visualization techniques to identify the flow. visualization techniques to identify the flow. Communicate & propose innovative solutions & strategies to Communicate & propose innovative solutions & strategies to business challenges. business challenges. Analyzed data for insights, trends, patterns & extracting key Analyzed data for insights, trends, patterns & extracting key information from structured & unstructured data. information from structured & unstructured data. Feature extraction, data wrangling, & data transformation Feature extraction, data wrangling, & data transformation infrastructure. infrastructure. Design, implement, & maintain Machine learning, NLP, GenAI Design, implement, & maintain Machine learning, NLP, GenAI modelling & algorithms. modelling & algorithms. Experience using ML & NLP libraries, such as scikit learn, Experience using ML & NLP libraries, such as scikit learn, Seaborn, Matplotlib, Pandas, Numpy, HuggingFace & Seaborn, Matplotlib, Pandas, Numpy, HuggingFace & LangChain ecosystem etc. LangChain ecosystem etc. Take ownership of the data science model end-to-end from Take ownership of the data science model end-to-end from data collection to model building. data collection to model building. Solid understanding of the mathematics related to data Solid understanding of the mathematics related to data sc"
    },
    "source": "resume",
    "confidence": 93,
    "processingTime": 0
  }
}